{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729b25b7-235d-49a3-ba7a-d321f154e500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/home/larend/kfx/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb5d131",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLFP_spk_preprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities_ketamine_analysis_v8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/kfx/simon/LFP_spk_preprocessing/utilities_ketamine_analysis_v8.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This example imports functions from the DemoReadSGLXData module to read\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# digital data. The metadata file must be present in the same directory as the binary file.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Works with both imec and nidq digital channels.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from src.simon.LFP_spk_preprocessing.utilities_ketamine_analysis_v8 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f654e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d092be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ghostipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cddef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mat73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to uncomment the following line if running this\n",
    "# notebook on Colab\n",
    "\n",
    "import ghostipy as gsp\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import os\n",
    "import h5py\n",
    "import warnings\n",
    "from urllib.request import urlopen\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz, iirnotch, welch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9761757",
   "metadata": {},
   "source": [
    "# Filenames to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c428d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "binPath = r'G:\\My Drive\\Fenton_Lab\\Ketamine_analysis\\Ketamine_data\\Neurotar_HPC_ketamine\\SPK\\electrophysiology\\\\'\n",
    "binFullPath = Path(binPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffe6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nt_Path for behavior\n",
    "#sync_path for sync pulse\n",
    "#ksort_path\n",
    "\n",
    "dlc_path = binFullPath.parents[1]\n",
    "\n",
    "files = dlc_path.glob('**/*.mat')\n",
    "\n",
    "sync_path=[]\n",
    "nt_path=[]\n",
    "\n",
    "for i in sorted(files):\n",
    "    \n",
    "    if 'sync' in str(i): \n",
    "        print(i)\n",
    "        sync_path.append(i)\n",
    "        \n",
    "    if 'behavior' in str(i): \n",
    "        print(i)\n",
    "        nt_path.append(i)\n",
    "\n",
    "print(nt_path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90a057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sync_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748af08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Example of how to append two files together\n",
    "dlc_path = binFullPath\n",
    "ksort_HPC_path=[]\n",
    "ksort_PFC_path=[]\n",
    "\n",
    "files = os.listdir(dlc_path)\n",
    "for i in sorted(files):\n",
    "            \n",
    "    if 'HPCprobe' in str(i): \n",
    "        ksort_HPC_path.append(Path(r'G:\\My Drive\\Fenton_Lab\\Ketamine_analysis\\Ketamine_data\\Neurotar_HPC_ketamine\\SPK\\electrophysiology\\\\' + i))\n",
    "        print(i)\n",
    "#     if 'PFCprobe' in str(i): \n",
    "#         ksort_PFC_path.append(Path(r'G:\\My Drive\\Fenton_Lab\\Ketamine_analysis\\Ketamine_data\\Neurotar_HPC_ketamine\\SPK\\electrophysiology\\\\' + i))      \n",
    "#         print(i)\n",
    "        \n",
    "print(ksort_HPC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b96fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "290a9cdb",
   "metadata": {},
   "source": [
    "# Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a112675",
   "metadata": {},
   "source": [
    "## Load behavior and sync files for aligment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183512d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nt_path),len(sync_path),len(ksort_HPC_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1f1ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mat73\n",
    "ts_ephys_aln = []\n",
    "nt_sync_aln = []\n",
    "camera_sync_aln = []\n",
    "ioFS = []\n",
    "x = []\n",
    "y = []\n",
    "yaw = []\n",
    "speed = []\n",
    "sync_bool = []\n",
    "\n",
    "for ipath in range(0,len(nt_path)):\n",
    "    \n",
    "    ipathsync = sync_path[ipath]\n",
    "    ipathnt = nt_path[ipath]\n",
    "\n",
    "    print('experiment',ipathsync)\n",
    "    \n",
    "    # raw files for sync and behavior\n",
    "    sync_extracted = mat73.loadmat(ipathsync)\n",
    "    behavior = loadmat(ipathnt)\n",
    "    \n",
    "    if np.abs(sync_extracted['samplesSyncAP_HPCprobe'].size - sync_extracted['samplesCamera'].size) < 1000:\n",
    "        \n",
    "        ts_ephys_aln.append(sync_extracted['samplesSyncAP_HPCprobe'])\n",
    "        nt_sync_aln.append(sync_extracted['samplesNeurotarStrobe'])\n",
    "        camera_sync_aln.append(sync_extracted['samplesCamera'])\n",
    "        ioFS.append(sync_extracted['ioFS'])\n",
    "        \n",
    "        x.append(behavior['nt_x'][0])\n",
    "        y.append(behavior['nt_y'][0])\n",
    "        yaw.append(behavior['nt_alpha'][0])\n",
    "        speed.append(behavior['nt_speed'][0])\n",
    "        \n",
    "        \n",
    "        sync_bool.append(True)\n",
    "        \n",
    "    else:\n",
    "        sync_bool.append(False)\n",
    "\n",
    "\n",
    "#     if 'SAL' in ipathsync:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sync_bool)\n",
    "sync_cond = (np.hstack(sync_bool))\n",
    "print(sync_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sync_ok = np.flatnonzero(sync_cond == True)\n",
    "idx_sync_ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321214ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Already alligned\n",
    "sync_path_matched = np.array(sync_path)[idx_sync_ok]\n",
    "nt_path_matched = np.array(nt_path)[idx_sync_ok]\n",
    "ksort_HPC_path_matched = np.array(ksort_HPC_path)[idx_sync_ok]\n",
    "# ksort_PFC_path_matched = np.array(ksort_PFC_path)[idx_sync_ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da1625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ksort_HPC_path_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d77a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos ndarray & list & DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb38825",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aln = []\n",
    "y_aln = []\n",
    "yaw_aln = []\n",
    "speed_aln = []\n",
    "duration = []\n",
    "idx_camera = []\n",
    "idx_camera_end = []\n",
    "idx_nt = []\n",
    "idx_nt_end = []\n",
    "\n",
    "for ipath in range(0,len(x)):\n",
    "    ipathsync = sync_path_matched[ipath]\n",
    "    print('experiment',ipathsync)\n",
    "\n",
    "    plt.plot(np.diff(ts_ephys_aln[ipath]))\n",
    "    plt.plot(np.diff(nt_sync_aln[ipath]))\n",
    "    plt.plot(np.diff(camera_sync_aln[ipath]))\n",
    "    plt.show()\n",
    "\n",
    "    print(camera_sync_aln[ipath])\n",
    "    print(nt_sync_aln[ipath])\n",
    "    \n",
    "    _tmp_idx = []\n",
    "    _tmp_idx = np.argwhere((camera_sync_aln[ipath] < nt_sync_aln[ipath][-1])==True)[-1]\n",
    "    \n",
    "    if ts_ephys_aln[ipath].size >= _tmp_idx:\n",
    "        #Just to allign the camera with the sync, having the first frame of behavior and the last one\n",
    "        idx_camera.append(np.argwhere((camera_sync_aln[ipath] > nt_sync_aln[ipath][0])==True)[0])\n",
    "        idx_camera_end.append(np.argwhere((camera_sync_aln[ipath] < nt_sync_aln[ipath][-1])==True)[-1])\n",
    " \n",
    "    if ts_ephys_aln[ipath].size < _tmp_idx:\n",
    "        #Just to allign the camera with the sync, having the first frame of behavior and the last one\n",
    "        idx_camera.append(np.argwhere((camera_sync_aln[ipath] > nt_sync_aln[ipath][0])==True)[0])\n",
    "        idx_camera_end.append(np.array([ts_ephys_aln[ipath].size-1]).astype(int))\n",
    "         \n",
    "    \n",
    "    print('camera',idx_camera[ipath],idx_camera_end[ipath])\n",
    "    print(idx_camera_end[ipath]-idx_camera[ipath])\n",
    "\n",
    "\n",
    "    print(ts_ephys_aln[ipath].size,nt_sync_aln[ipath].size,camera_sync_aln[ipath].size)\n",
    "\n",
    "\n",
    "    duration.append(((ts_ephys_aln[ipath][idx_camera_end[ipath]] - ts_ephys_aln[ipath][idx_camera[ipath]]) /30000)[0])\n",
    "\n",
    "    idx_nt.append(np.argwhere((nt_sync_aln[ipath] > camera_sync_aln[ipath][idx_camera[ipath]])==True)[0])\n",
    "    idx_nt_end.append(np.argwhere((nt_sync_aln[ipath] < camera_sync_aln[ipath][idx_camera_end[ipath]])==True)[-1])\n",
    "    print('nt',idx_nt[ipath],idx_nt_end[ipath])\n",
    "\n",
    "    print(duration,(nt_sync_aln[ipath][idx_nt_end[ipath]] - nt_sync_aln[ipath][idx_nt[ipath]]) /ioFS)\n",
    "    print('Deviation of',(duration[ipath] - (nt_sync_aln[ipath][idx_nt_end[ipath]] - nt_sync_aln[ipath][idx_nt[ipath]]) /ioFS[ipath]) * 1000, 'in miliseconds')\n",
    "    print('Deviation at start',((camera_sync_aln[ipath][idx_camera[ipath]] - nt_sync_aln[ipath][idx_nt[ipath]])/ioFS[ipath]) * 1000,'in miliseconds')\n",
    "    print('Deviation at end',((camera_sync_aln[ipath][idx_camera_end[ipath]] - nt_sync_aln[ipath][idx_nt_end[ipath]])/ioFS[ipath]) * 1000,'in miliseconds')\n",
    "\n",
    "    \n",
    "    \n",
    "    ## align behavior\n",
    "\n",
    "    x_aln.append(x[ipath][int(idx_nt[ipath][0]):int(idx_nt_end[ipath][0])])\n",
    "    y_aln.append(y[ipath][int(idx_nt[ipath][0]):int(idx_nt_end[ipath][0])])\n",
    "    yaw_aln.append(yaw[ipath][int(idx_nt[ipath][0]):int(idx_nt_end[ipath][0])])\n",
    "    speed_aln.append(speed[ipath][int(idx_nt[ipath][0]):int(idx_nt_end[ipath][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get lfp paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b0c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Example of how to append two files together\n",
    "path_lfp = Path(r'Z:\\NeuroPix\\Ketamine\\\\')\n",
    "dlc_path = path_lfp\n",
    "\n",
    "files = dlc_path.glob('**/*.imec1.lf.bin')\n",
    "HPC_lfp_path=[]\n",
    "\n",
    "# files = os.listdir(dlc_path)\n",
    "\n",
    "for i in files:\n",
    "    \n",
    "    if 'De_nosing' in str(i):\n",
    "        break    \n",
    "        \n",
    "    HPC_lfp_path.append(i)\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(HPC_lfp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split path by \\\n",
    "root_lfp = []\n",
    "for i in HPC_lfp_path:\n",
    "\n",
    "    arr = []\n",
    "    arr = [ x.strip() for x in str(i).split('\\\\') ]\n",
    "    \n",
    "    naming_convention = []\n",
    "    naming_convention = arr[3]\n",
    "    new = np.char.replace(naming_convention,'-','_')\n",
    "\n",
    "    print(naming_convention)\n",
    "    root_lfp.append(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e35bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split path by \\\n",
    "HPC_lfp_path_matched = []\n",
    "for i in ksort_HPC_path_matched:\n",
    "\n",
    "    arr = []\n",
    "    arr = [ x.strip() for x in str(i).split('\\\\') ]\n",
    "    \n",
    "    naming_convention = []\n",
    "    naming_convention = arr[-1][:-9]\n",
    "    new = []\n",
    "    new = np.char.replace(naming_convention,'-','_')\n",
    "    print(new)\n",
    "    \n",
    "    idx = root_lfp.index(new)\n",
    "    \n",
    "    print(HPC_lfp_path[idx])\n",
    "    \n",
    "    HPC_lfp_path_matched.append(HPC_lfp_path[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPC_lfp_path_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b29938",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(HPC_lfp_path_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151d5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec44ad79",
   "metadata": {},
   "source": [
    "# about 2-3 min until this point !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1118c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## save paths\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# outputlist = []\n",
    "# outputlist = [HPC_lfp_path_matched, x_aln, y_aln, yaw_aln, speed_aln,ksort_HPC_path_matched]\n",
    "\n",
    "# # to save \"processed\" aligned data\n",
    "# with open(r'C:\\Users\\fentonlab\\Desktop\\Local_copy_Ketamine_analysis\\HPC_path_info_behavior.file', 'wb') as f:\n",
    "#     pickle.dump(outputlist, f, pickle.HIGHEST_PROTOCOL)\n",
    "# print('saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8841c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load behavior and path data\n",
    "\n",
    "import pickle\n",
    "\n",
    "HPC_lfp_path_matched, x_aln, y_aln, yaw_aln, speed_aln,ksort_HPC_path_matched = [],[],[],[],[],[]\n",
    "\n",
    "# load data\n",
    "with open(r'C:\\Users\\fentonlab\\Desktop\\Local_copy_Ketamine_analysis\\HPC_path_info_behavior.file', 'rb') as f3:\n",
    "    [HPC_lfp_path_matched, x_aln, y_aln, yaw_aln, speed_aln,ksort_HPC_path_matched] = pickle.load(f3)    \n",
    "print('loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76d2a5",
   "metadata": {},
   "source": [
    "### Electrophysiology - Load units - HPC probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dabf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### file to load\n",
    "ipath = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin = 0.01 # 1/1250 # in seconds; fine time resolution for phase-frequency analysis for PC and non-PCs analysis\n",
    "\n",
    "fs = 30000\n",
    "\n",
    "ksort_path = ksort_HPC_path_matched[ipath]\n",
    "print('experiment',ksort_path)\n",
    "\n",
    "cluster_info = []\n",
    "cluster_info_path = ksort_path.joinpath('cluster_info.tsv')\n",
    "cluster_group_path = ksort_path.joinpath('cluster_group.tsv')\n",
    "\n",
    "try:\n",
    "    cluster_info = pd.read_csv(cluster_info_path, sep='\\t')\n",
    "except:\n",
    "    cluster_info = pd.read_csv(cluster_group_path, sep='\\t')\n",
    "\n",
    "# for screening look only at good units \n",
    "try:\n",
    "    #cluster_info = cluster_info[cluster_info.group != 'noise']\n",
    "    cluster_info = cluster_info[cluster_info.KSLabel == 'good']\n",
    "\n",
    "#    cluster_info = cluster_info[cluster_info.group == 'good']\n",
    "#    cluster_info = cluster_info[cluster_info.n_spikes > 100]\n",
    "#    cluster_info = cluster_info[(cluster_info.group == 'good') * (cluster_info.depth > 1200)]\n",
    "\n",
    "except:\n",
    "    print('phy was not done')\n",
    "    cluster_info = cluster_info[cluster_info.KSLabel == 'good']\n",
    "    #cluster_info = cluster_info[cluster_info.KSLabel != 'noise']\n",
    "\n",
    "\n",
    "spike_times = np.load(ksort_path.joinpath('spike_times.npy'))\n",
    "spike_clusters = np.load(ksort_path.joinpath('spike_clusters.npy'))\n",
    "templates = np.load(ksort_path.joinpath('templates.npy'))\n",
    "spike_templates = np.load(ksort_path.joinpath('spike_templates.npy'))\n",
    "\n",
    "# cid_channels = dict(zip(cluster_info.id.values, cluster_info.ch.values))\n",
    "# cid_depth = dict(zip(cluster_info.id.values, cluster_info.depth.values))\n",
    "\n",
    "df_spikes = pd.DataFrame({'times':spike_times.flatten()/30000.0, \n",
    "           'unit_id':spike_clusters.flatten(), \n",
    "           'templates':spike_templates.flatten() })\n",
    "df_spikes.unit_id.unique().size\n",
    "\n",
    "\n",
    "\n",
    "    # remove noise units\n",
    "try:\n",
    "    kslabel_d = dict(zip(cluster_info.id, cluster_info.group))\n",
    "except:\n",
    "    kslabel_d = dict(zip(cluster_info.cluster_id, cluster_info.KSLabel))\n",
    "\n",
    "df_spikes['kslabel'] = df_spikes.unit_id.map(kslabel_d)\n",
    "# remove noise units\n",
    "df_spikes = df_spikes.dropna()\n",
    "#     df_spikes_all.append(df_spikes)\n",
    "print('allcells',df_spikes.unit_id.unique().size)\n",
    "\n",
    "#     cids_to_keep = []\n",
    "#     cids_to_keep = cluster_info[cluster_info['ch'].isin(ch_HPC_list[ipath])].cluster_id.values    \n",
    "# #     print(cids_to_keep)\n",
    "#     cids_to_keep_HPC_all.append(cids_to_keep)\n",
    "\n",
    "start_offset = []\n",
    "start_offset = int(ts_ephys_aln[ipath][idx_camera[ipath]])\n",
    "print(start_offset,start_offset/fs)\n",
    "\n",
    "\n",
    "## start with neurotar light recording\n",
    "df_spk = []\n",
    "df_spk = df_spikes.copy()\n",
    "df_spk['spk'] = df_spikes['times']\n",
    "\n",
    "\n",
    "df_spk= df_spk[(df_spk['spk'] >= (ts_ephys_aln[ipath][idx_camera[ipath]]/fs)[0]) & (df_spk['spk'] <= (ts_ephys_aln[ipath][idx_camera_end[ipath]]/fs)[0])]\n",
    "df_spk.head()\n",
    "\n",
    "df_spk['spk'] = df_spk['times'] - (ts_ephys_aln[ipath][idx_camera[ipath]]/fs)[0]\n",
    "df_spk['spk'] \n",
    "\n",
    "\n",
    "df_units = []\n",
    "df_units = bin_spk(df_spk, time_bin)  #0.01 is the time resolution to bin 0.01 s = 10ms\n",
    "\n",
    "\n",
    "_inp_l = []\n",
    "#     _inp_l = df_units[df_units['cids'].isin(cids_to_keep)].pivot('cids', 'times', 'hz').values[:, :]\n",
    "_inp_l = df_units.pivot('cids', 'times', 'hz').values[:, :]\n",
    "\n",
    "print('shape binned', _inp_l.shape)\n",
    "\n",
    "spk_tmp = []\n",
    "\n",
    "cids_good = []\n",
    "cids_good = df_units.cids.unique()\n",
    "print(cids_good.size)\n",
    "\n",
    "channel_good = []\n",
    "channel_good = cluster_info[cluster_info['cluster_id'].isin(cids_good)].ch.values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817d0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputlist = []\n",
    "outputlist = [_inp_l, cids_good, channel_good]\n",
    "\n",
    "import pickle\n",
    "# to save \"processed\" aligned data\n",
    "with open(r'C:\\Users\\fentonlab\\Desktop\\Local_copy_Ketamine_analysis\\spk_' + str(ipath) + '.file' , 'wb') as f:\n",
    "    pickle.dump(outputlist, f, pickle.HIGHEST_PROTOCOL)\n",
    "print('saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75dcb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4db1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
